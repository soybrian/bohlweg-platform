# Bohlweg Platform - Development Guide

**FÃ¼r Claude und andere Entwickler**

Dieses Dokument beschreibt die interne Architektur und Entwicklungs-Workflows der Bohlweg Platform.

## ğŸ—ï¸ Architektur-Ãœbersicht

### Tech Stack

- **Frontend:** Next.js 15 (App Router), React 19, TypeScript
- **Styling:** Tailwind CSS mit Glass Fluid Design
- **Database:** SQLite (better-sqlite3)
- **Scraping:** Playwright fÃ¼r robustes Browser-Automation
- **Scheduling:** node-cron fÃ¼r zeitgesteuerte Scraper-AusfÃ¼hrung
- **Deployment:** Docker & Docker Compose

### Design Patterns

1. **Modulares Design:** Jeder Scraper ist ein unabhÃ¤ngiges Modul
2. **Repository Pattern:** Datenbank-Operationen sind in `lib/db/index.ts` gekapselt
3. **Separation of Concerns:** UI, Business Logic und Data Layer sind getrennt
4. **API Routes:** RESTful API fÃ¼r Frontend-Backend-Kommunikation

## ğŸ“ Projekt-Struktur (Detailliert)

```
bohlweg-platform/
â”‚
â”œâ”€â”€ app/                              # Next.js App Router (React 19)
â”‚   â”œâ”€â”€ api/                          # API Routes (Server-Side)
â”‚   â”‚   â”œâ”€â”€ ideas/route.ts           # GET /api/ideas - Ideenplattform Daten
â”‚   â”‚   â”œâ”€â”€ maengel/route.ts         # GET /api/maengel - MÃ¤ngelmelder Daten
â”‚   â”‚   â””â”€â”€ stats/route.ts           # GET /api/stats - Dashboard Statistiken
â”‚   â”œâ”€â”€ globals.css                   # Global Styles + Glass Fluid CSS
â”‚   â”œâ”€â”€ layout.tsx                    # Root Layout mit Gradient Background
â”‚   â””â”€â”€ page.tsx                      # Dashboard mit Live-Suche und Stats
â”‚
â”œâ”€â”€ components/                       # Wiederverwendbare React Komponenten
â”‚   â””â”€â”€ (Platz fÃ¼r zukÃ¼nftige Komponenten)
â”‚
â”œâ”€â”€ lib/                              # Shared Libraries
â”‚   â”œâ”€â”€ db/                           # Database Layer
â”‚   â”‚   â”œâ”€â”€ index.ts                 # DB Operations (CRUD, Stats, Scraper Runs)
â”‚   â”‚   â””â”€â”€ schema.ts                # Schema Definitionen + SQL DDL
â”‚   â””â”€â”€ utils.ts                      # Utility Functions (cn, formatDate, etc.)
â”‚
â”œâ”€â”€ scrapers/                         # Scraper Module
â”‚   â”œâ”€â”€ ideenplattform.ts            # Ideenplattform Scraper mit Playwright
â”‚   â”œâ”€â”€ maengelmelder.ts             # MÃ¤ngelmelder Scraper mit Playwright
â”‚   â””â”€â”€ scheduler.ts                  # Cron Scheduler fÃ¼r alle Scraper
â”‚
â”œâ”€â”€ data/                             # SQLite Database (automatisch erstellt)
â”‚   â””â”€â”€ bohlweg.db                    # SQLite Database File
â”‚
â”œâ”€â”€ public/                           # Statische Assets
â”‚
â”œâ”€â”€ docker-compose.yml                # Docker Compose fÃ¼r multi-container setup
â”œâ”€â”€ Dockerfile                        # Docker Build Configuration
â”œâ”€â”€ .gitignore                        # Git Ignore Rules
â”œâ”€â”€ next.config.ts                    # Next.js Configuration
â”œâ”€â”€ package.json                      # Dependencies und Scripts
â”œâ”€â”€ postcss.config.mjs                # PostCSS Config fÃ¼r Tailwind
â”œâ”€â”€ tailwind.config.ts                # Tailwind CSS Configuration
â”œâ”€â”€ tsconfig.json                     # TypeScript Configuration
â”œâ”€â”€ README.md                         # User-facing Documentation
â””â”€â”€ DEVELOPMENT.md                    # This file
```

## ğŸ”§ Entwicklungs-Workflow

### 1. Setup

```bash
# Dependencies installieren
npm install

# Playwright Browser installieren
npx playwright install chromium

# Dev Server starten
npm run dev
```

### 2. Scraper entwickeln/testen

```bash
# Einzelnen Scraper testen
npx ts-node scrapers/ideenplattform.ts
npx ts-node scrapers/maengelmelder.ts

# Alle Scraper sofort ausfÃ¼hren
npx ts-node scrapers/scheduler.ts --now

# Scheduler im Entwicklungs-Modus starten
npx ts-node scrapers/scheduler.ts --initial
```

### 3. Datenbank inspizieren

```bash
# SQLite CLI Ã¶ffnen
sqlite3 data/bohlweg.db

# NÃ¼tzliche SQL Queries:
.tables                          # Alle Tabellen anzeigen
SELECT * FROM ideas LIMIT 5;     # Erste 5 Ideen
SELECT * FROM maengel LIMIT 5;   # Erste 5 MÃ¤ngel
SELECT * FROM scraper_runs;      # Scraper History
```

### 4. API testen

```bash
# Mit curl
curl "http://localhost:3000/api/ideas"
curl "http://localhost:3000/api/ideas?category=Verkehr&limit=5"
curl "http://localhost:3000/api/maengel?search=Fahrrad"
curl "http://localhost:3000/api/stats"

# Mit httpie (wenn installiert)
http localhost:3000/api/ideas
http localhost:3000/api/stats
```

## ğŸ—„ï¸ Datenbank-Schema

### Ideas Table

```sql
CREATE TABLE ideas (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  externalId TEXT UNIQUE NOT NULL,    -- ID von der Website
  title TEXT NOT NULL,
  description TEXT,
  author TEXT,
  category TEXT,
  status TEXT,
  supporters INTEGER DEFAULT 0,
  maxSupporters INTEGER DEFAULT 50,
  comments INTEGER DEFAULT 0,
  createdAt TEXT,
  url TEXT,
  scraped_at TEXT NOT NULL
);
```

### Maengel Table

```sql
CREATE TABLE maengel (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  externalId TEXT UNIQUE NOT NULL,
  title TEXT NOT NULL,
  description TEXT,
  author TEXT,
  category TEXT,
  status TEXT,
  location TEXT,                      -- Adresse/Standort
  createdAt TEXT,
  url TEXT,
  scraped_at TEXT NOT NULL
);
```

### Scraper Runs Table

```sql
CREATE TABLE scraper_runs (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  module TEXT NOT NULL,               -- 'ideenplattform' oder 'maengelmelder'
  startTime TEXT NOT NULL,
  endTime TEXT,
  itemsScraped INTEGER DEFAULT 0,
  itemsNew INTEGER DEFAULT 0,
  itemsUpdated INTEGER DEFAULT 0,
  success BOOLEAN DEFAULT 0,
  error TEXT
);
```

## ğŸ”„ Scraper-Logik

### Workflow eines Scrapers

1. **Start:** `startScraperRun()` - Erstellt Eintrag in `scraper_runs`
2. **Navigate:** Playwright Ã¶ffnet Browser und navigiert zur Seite
3. **Extract:** Daten werden aus HTML extrahiert
4. **Upsert:** `upsertIdea()` / `upsertMaengel()` - Insert oder Update
5. **Pagination:** Weiter zur nÃ¤chsten Seite (wenn vorhanden)
6. **End:** `endScraperRun()` - Aktualisiert Statistiken

### Error Handling

- **Try-Catch:** Jeder Scraper hat globales try-catch
- **Item-Level:** Fehler bei einzelnen Items werden geloggt, aber nicht geworfen
- **Graceful Degradation:** Bei Fehler werden bereits gesammelte Daten gespeichert
- **Logging:** Alle Fehler werden in `scraper_runs.error` gespeichert

### Anti-Blocking MaÃŸnahmen

- **Delay:** 1 Sekunde Pause zwischen Seiten-Requests
- **User Agent:** Playwright verwendet realistischen Browser
- **Headless:** Kann auf `false` gesetzt werden fÃ¼r Debugging

## ğŸ¨ UI/UX Design

### Glass Fluid Style

Das UI verwendet Glasmorphismus-Effekte:

```css
.glass {
  @apply bg-white/10 backdrop-blur-lg border border-white/20 shadow-xl;
}

.glass-card {
  @apply glass rounded-2xl p-6 transition-all duration-300
         hover:bg-white/20 hover:shadow-2xl;
}
```

### Responsive Design

- **Mobile First:** Design startet bei 320px
- **Breakpoints:** sm (640px), md (768px), lg (1024px), xl (1280px)
- **Flexbox & Grid:** FÃ¼r responsive Layouts

### Animations

- **fade-in:** Staggered entrance animations
- **hover-lift:** Subtle hover elevation
- **fluid-animation:** Pulsing effects fÃ¼r Live-Data

## ğŸ“¡ API Design

### RESTful Conventions

- **GET /api/ideas** - Liste aller Ideen
- **GET /api/maengel** - Liste aller MÃ¤ngel
- **GET /api/stats** - Dashboard Statistiken

### Query Parameters

Alle List-Endpoints unterstÃ¼tzen:
- `category` - Filter nach Kategorie
- `status` - Filter nach Status
- `search` - Volltextsuche
- `limit` - Max. Anzahl Ergebnisse
- `offset` - Pagination

### Response Format

```json
// GET /api/ideas
[
  {
    "id": 1,
    "externalId": "32181",
    "title": "FahrradabstellplÃ¤tze",
    "description": "Mehr FahrradabstellplÃ¤tze am Rudolfplatz",
    "author": "hallo",
    "category": "Verkehr",
    "status": "Laufend",
    "supporters": 1,
    "maxSupporters": 50,
    "comments": 0,
    "createdAt": "Mi., 08.10.2025 - 20:02",
    "url": "https://mitreden.braunschweig.de/node/32181",
    "scraped_at": "2025-10-09T18:30:00.000Z"
  }
]
```

## ğŸ³ Docker

### Development mit Docker

```bash
# Build Image
docker build -t bohlweg-platform .

# Run Container
docker run -p 3000:3000 -v $(pwd)/data:/app/data bohlweg-platform

# Mit Docker Compose
docker-compose up -d
docker-compose logs -f
docker-compose down
```

### Multi-Container Setup

- **web:** Next.js Application (Port 3000)
- **scraper:** Cron Scheduler (shared database)

## ğŸ§ª Testing

### Manual Testing Checklist

- [ ] Dashboard lÃ¤dt und zeigt Statistiken
- [ ] Live-Suche funktioniert
- [ ] Tab-Wechsel zwischen Ideen und MÃ¤ngel
- [ ] Links zu externen Seiten funktionieren
- [ ] Mobile Ansicht ist responsive
- [ ] Scraper laufen ohne Fehler
- [ ] API Endpoints liefern korrek Daten
- [ ] Docker Build funktioniert

## ğŸš€ Deployment

### Production Build

```bash
npm run build
npm start
```

### Environment Variables

```env
NODE_ENV=production
NEXT_TELEMETRY_DISABLED=1
```

### Docker Deployment

```bash
docker-compose up -d
```

## ğŸ”„ Erweiterungen

### Neues Modul hinzufÃ¼gen

1. **Scraper erstellen** in `scrapers/new-module.ts`
2. **Schema erweitern** in `lib/db/schema.ts`
3. **DB Ops** in `lib/db/index.ts`
4. **API Route** in `app/api/new-module/route.ts`
5. **Scheduler** in `scrapers/scheduler.ts` erweitern
6. **UI** in `app/page.tsx` anpassen

### Bekannte Kategorien

**Ideenplattform:**
- Finanzen
- Verkehr
- Schule und Kultur
- Allgemeine Verwaltung
- StadtgrÃ¼n und Umwelt
- Wirtschaft
- Soziales, Jugend und Gesundheit
- Recht, Sicherheit und Ordnung
- Bauen und Planung

**MÃ¤ngelmelder:**
- Poller defekt
- Ampel defekt (Taste/Licht)
- Illegale Plakatierung
- Wilde MÃ¼llkippe, SperrmÃ¼llreste
- StraÃŸenschild / Verkehrszeichen defekt
- StraÃŸenkanaldeckel defekt
- StraÃŸen-, Radweg- und GehwegschÃ¤den
- Gully / Bachablauf verstopft
- Friedhofsunterhaltung
- abgemeldete Fahrzeuge
- Fahrradwracks
- StraÃŸenbeleuchtung / Laterne defekt
- Spielplatzunterhaltung

## ğŸ“š NÃ¼tzliche Ressourcen

- [Next.js Docs](https://nextjs.org/docs)
- [Playwright Docs](https://playwright.dev)
- [Tailwind CSS](https://tailwindcss.com/docs)
- [better-sqlite3](https://github.com/WiseLibs/better-sqlite3)
- [node-cron](https://github.com/node-cron/node-cron)

## ğŸ› Known Issues

### Scraper

- [ ] Pagination kÃ¶nnte bei sehr vielen Seiten optimiert werden
- [ ] Category/Status Erkennung kÃ¶nnte robuster sein
- [ ] Keine Retry-Logik bei temporÃ¤ren Netzwerkfehlern

### UI

- [ ] Keine Dark Mode Toggle (nur durch System)
- [ ] Keine Persistierung von Such-Queries
- [ ] Keine Benachrichtigungen bei neuen Daten

### Database

- [ ] Keine Volltextsuche-Indizes (FTRE)
- [ ] Keine Auto-Cleanup von alten Daten
- [ ] Keine Backups

## ğŸ’¡ Future Ideas

- [ ] GraphQL API fÃ¼r komplexere Queries
- [ ] WebSocket fÃ¼r Live-Updates
- [ ] Admin Panel fÃ¼r manuelle Scraper-Steuerung
- [ ] Export-Funktionen (CSV, JSON, PDF)
- [ ] Email-Benachrichtigungen bei neuen Ideen/MÃ¤ngeln
- [ ] Sentiment-Analyse der Beschreibungen
- [ ] Geo-Visualisierung der MÃ¤ngel auf Karte
- [ ] Trending-Algorithmus fÃ¼r wichtige Themen
- [ ] RSS Feed fÃ¼r Journalisten

## ğŸ“ Code Style

- **TypeScript:** Strict mode enabled
- **Naming:** camelCase fÃ¼r Variablen, PascalCase fÃ¼r Types/Interfaces
- **Comments:** JSDoc fÃ¼r Funktionen, Inline fÃ¼r komplexe Logik
- **Async:** async/await bevorzugt Ã¼ber Promises
- **Error Handling:** Explizite try-catch BlÃ¶cke

---

**Happy Coding! ğŸš€**
