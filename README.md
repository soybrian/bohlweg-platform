# Bohlweg Platform

**Modulare Informationsplattform fÃ¼r Braunschweiger Journalisten**

Bohlweg ist eine performante, modulbasierte Plattform, die stÃ¤dtische Informationen aus Braunschweig aggregiert und in einem modernen Dashboard prÃ¤sentiert. Die Plattform scrapt automatisch Daten von verschiedenen Quellen und stellt sie fÃ¼r Journalisten Ã¼bersichtlich dar.

## ğŸ“‹ Features

- âœ¨ **Glass Fluid Design** - Modernes, mobil-optimiertes UI mit Glasmorphismus-Effekten
- ğŸ”„ **Asynchrones Scraping** - Performantes, nicht-blockierendes Daten-Scraping
- ğŸ—‚ï¸ **Modulare Architektur** - Einfach erweiterbar mit neuen Datenquellen
- ğŸ” **Live-Suche** - Echtzeit-Filterung durch alle DatensÃ¤tze
- ğŸ“Š **Dashboard mit Statistiken** - Ãœbersichtliche Darstellung aller wichtigen Metriken
- ğŸ“± **Mobile First** - VollstÃ¤ndig responsive und fÃ¼r mobile GerÃ¤te optimiert
- ğŸ³ **Docker-Support** - Einfaches Deployment mit Docker

## ğŸ—ï¸ Architektur

```
bohlweg-platform/
â”œâ”€â”€ app/                      # Next.js App Router
â”‚   â”œâ”€â”€ api/                  # API Routes
â”‚   â”‚   â”œâ”€â”€ ideas/           # Ideenplattform API
â”‚   â”‚   â”œâ”€â”€ maengel/         # MÃ¤ngelmelder API
â”‚   â”‚   â””â”€â”€ stats/           # Statistik API
â”‚   â”œâ”€â”€ globals.css          # Globale Styles mit Glass Fluid Effekten
â”‚   â”œâ”€â”€ layout.tsx           # Root Layout
â”‚   â””â”€â”€ page.tsx             # Haupt-Dashboard
â”œâ”€â”€ components/              # React Komponenten (erweiterbar)
â”œâ”€â”€ lib/                     # Shared Libraries
â”‚   â”œâ”€â”€ db/                  # Datenbank-Layer
â”‚   â”‚   â”œâ”€â”€ index.ts        # DB Operations
â”‚   â”‚   â””â”€â”€ schema.ts       # Schema Definitionen
â”‚   â””â”€â”€ utils.ts            # Utility Functions
â”œâ”€â”€ scrapers/                # Scraper Module
â”‚   â”œâ”€â”€ ideenplattform.ts   # Ideenplattform Scraper
â”‚   â”œâ”€â”€ maengelmelder.ts    # MÃ¤ngelmelder Scraper
â”‚   â””â”€â”€ scheduler.ts        # Cron Scheduler
â”œâ”€â”€ data/                    # SQLite Datenbank (wird automatisch erstellt)
â”œâ”€â”€ public/                  # Statische Assets
â”œâ”€â”€ docker-compose.yml       # Docker Compose Config
â”œâ”€â”€ Dockerfile              # Docker Build Config
â””â”€â”€ README.md               # Diese Datei
```

## ğŸš€ Quick Start

### Voraussetzungen

- Node.js 18+
- npm oder yarn
- (Optional) Docker & Docker Compose

### Installation

1. **Repository klonen und Dependencies installieren**

```bash
cd bohlweg-platform
npm install
```

2. **Playwright Browser installieren**

```bash
npx playwright install chromium
```

3. **Datenbank initialisieren**

Die Datenbank wird automatisch beim ersten Start erstellt. Optional kann sie manuell initialisiert werden:

```bash
npm run setup-db
```

4. **Entwicklungsserver starten**

```bash
npm run dev
```

Die Anwendung ist nun unter `http://localhost:3000` erreichbar.

## ğŸ“Š Module

### 1. Ideenplattform Scraper

Scrapt BÃ¼rger-Ideen von https://mitreden.braunschweig.de/ideenplattform

**Gesammelte Daten:**
- Titel und Beschreibung der Idee
- Autor und Erstellungsdatum
- Kategorie (Verkehr, StadtgrÃ¼n, etc.)
- Status (Laufend, Umgesetzt, etc.)
- UnterstÃ¼tzer-Anzahl
- Kommentar-Anzahl

**Manuell ausfÃ¼hren:**
```bash
npx ts-node scrapers/ideenplattform.ts
```

### 2. MÃ¤ngelmelder Scraper

Scrapt gemeldete MÃ¤ngel von https://mitreden.braunschweig.de/maengelmelder

**Gesammelte Daten:**
- Titel und Beschreibung des Mangels
- Autor und Meldedatum
- Kategorie (StraÃŸenschÃ¤den, Beleuchtung, etc.)
- Bearbeitungsstatus
- Standort/Adresse

**Manuell ausfÃ¼hren:**
```bash
npx ts-node scrapers/maengelmelder.ts
```

### 3. Scheduler

FÃ¼hrt die Scraper automatisch in regelmÃ¤ÃŸigen AbstÃ¤nden aus.

**Standard-Schedule:**
- Ideenplattform: TÃ¤glich um 6:00 Uhr
- MÃ¤ngelmelder: TÃ¤glich um 6:30 Uhr

**Scheduler starten:**
```bash
npm run scraper
```

**Alle Scraper sofort ausfÃ¼hren:**
```bash
npx ts-node scrapers/scheduler.ts --now
```

**Nur Ideenplattform scrapen:**
```bash
npx ts-node scrapers/scheduler.ts --ideenplattform
```

**Nur MÃ¤ngelmelder scrapen:**
```bash
npx ts-node scrapers/scheduler.ts --maengelmelder
```

## ğŸ¨ Dashboard Features

### Live-Suche
- Durchsucht alle Titel, Beschreibungen, Kategorien und Standorte
- Echtzeit-Filterung ohne Seiten-Reload
- Funktioniert sowohl fÃ¼r Ideen als auch MÃ¤ngel

### Statistiken
- Gesamt-Anzahl Ideen und MÃ¤ngel
- Verteilung nach Kategorien
- Verteilung nach Status
- Aktuelle Scraper-Runs

### Filter
- Nach Kategorie filtern
- Nach Status filtern
- Kombinierbar mit Suche

## ğŸ—„ï¸ Datenbank

Die Plattform verwendet **SQLite** (better-sqlite3) fÃ¼r optimale Performance.

**Tabellen:**
- `ideas` - Ideen von der Ideenplattform
- `maengel` - MÃ¤ngel vom MÃ¤ngelmelder
- `scraper_runs` - History der Scraper-AusfÃ¼hrungen

**Datenbank-Pfad:**
```
data/bohlweg.db
```

## ğŸ³ Docker Deployment (Production)

### Voraussetzungen

- Docker 20.10+
- Docker Compose v2.0+

### Environment-Variablen konfigurieren

Erstelle eine `.env` Datei basierend auf `.env.example`:

```bash
cp .env.example .env
```

**Wichtige Production-Einstellungen:**

```bash
# .env
NODE_ENV=production
NEXT_TELEMETRY_DISABLED=1
DATABASE_PATH=/app/data/bohlweg.db
PORT=3000
```

### Production Build erstellen

```bash
# 1. Production Build testen
npm run build

# 2. Docker Image bauen
docker-compose build

# 3. Container starten
docker-compose up -d
```

Die Anwendung lÃ¤uft auf Port 3000 mit:
- **Web-Service**: Next.js Application (http://localhost:3000)
- **Scraper-Service**: Automatischer Scheduler fÃ¼r tÃ¤gliches Scraping

### Docker-Container verwalten

```bash
# Status anzeigen
docker-compose ps

# Logs anzeigen
docker-compose logs -f web
docker-compose logs -f scraper

# Container stoppen
docker-compose stop

# Container neu starten
docker-compose restart

# Container stoppen und entfernen
docker-compose down

# Container stoppen und Volumes lÃ¶schen (ACHTUNG: Datenbank wird gelÃ¶scht!)
docker-compose down -v
```

### Production-Datenbank-Backup

```bash
# Backup erstellen
docker-compose exec web cp /app/data/bohlweg.db /app/data/bohlweg-backup-$(date +%Y%m%d).db

# Oder von Host-System
cp data/bohlweg.db data/bohlweg-backup-$(date +%Y%m%d).db
```

### Health Check

Die Docker-Container haben integrierte Health Checks:

```bash
# Health Status prÃ¼fen
docker-compose ps

# Manual health check
curl http://localhost:3000/api/stats
```

### Nur Docker (ohne Compose)

```bash
# Image bauen
docker build -t bohlweg-platform .

# Container starten
docker run -d \
  --name bohlweg-web \
  -p 3000:3000 \
  -v $(pwd)/data:/app/data \
  -e NODE_ENV=production \
  -e NEXT_TELEMETRY_DISABLED=1 \
  --restart unless-stopped \
  bohlweg-platform
```

### Production-Checkliste

- [ ] `.env` Datei mit Production-Werten erstellt
- [ ] `npm run build` erfolgreich durchgefÃ¼hrt
- [ ] Docker-Container mit Health Checks gestartet
- [ ] Datenbank-Backups konfiguriert
- [ ] Logs werden Ã¼berwacht
- [ ] Port 3000 ist erreichbar (oder via Reverse Proxy)

## ğŸ”§ Konfiguration

### Scraper-Schedule anpassen

Bearbeite `scrapers/scheduler.ts`:

```typescript
const CONFIG = {
  ideenplattform: {
    schedule: "0 6 * * *", // Cron-Format
    maxPages: 5,
    enabled: true,
  },
  // ...
};
```

### Cron-Format

```
* * * * *
â”‚ â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ â”‚ â””â”€ Wochentag (0-7)
â”‚ â”‚ â”‚ â””â”€â”€â”€ Monat (1-12)
â”‚ â”‚ â””â”€â”€â”€â”€â”€ Tag (1-31)
â”‚ â””â”€â”€â”€â”€â”€â”€â”€ Stunde (0-23)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€ Minute (0-59)
```

**Beispiele:**
- `0 6 * * *` - TÃ¤glich um 6:00 Uhr
- `*/30 * * * *` - Alle 30 Minuten
- `0 */6 * * *` - Alle 6 Stunden
- `0 0 * * 0` - Jeden Sonntag um Mitternacht

## ğŸ“ API Endpoints

### GET /api/ideas
Liefert alle Ideen

**Query Parameter:**
- `category` - Filter nach Kategorie
- `status` - Filter nach Status
- `search` - Volltextsuche
- `limit` - Max. Anzahl Ergebnisse (default: 50)
- `offset` - Pagination Offset

**Beispiel:**
```bash
curl "http://localhost:3000/api/ideas?category=Verkehr&limit=10"
```

### GET /api/maengel
Liefert alle MÃ¤ngel

**Query Parameter:** Wie /api/ideas

### GET /api/stats
Liefert Dashboard-Statistiken

## ğŸ§ª Development

### Build fÃ¼r Production

```bash
npm run build
npm start
```

### TypeScript kompilieren

```bash
npx tsc
```

### Linting

```bash
npm run lint
```

## ğŸ†• Neue Module hinzufÃ¼gen

1. **Neuen Scraper erstellen**

Erstelle eine neue Datei in `scrapers/`:

```typescript
// scrapers/new-module.ts
import { chromium } from "playwright";

export async function scrapeNewModule() {
  // Scraping-Logik
}
```

2. **Datenbank-Schema erweitern**

FÃ¼ge neues Interface und Tabelle in `lib/db/schema.ts` hinzu.

3. **DB-Operationen hinzufÃ¼gen**

Erweitere `lib/db/index.ts` mit CRUD-Operationen.

4. **API Route erstellen**

Erstelle neue Route in `app/api/new-module/route.ts`.

5. **Scheduler erweitern**

FÃ¼ge neues Modul in `scrapers/scheduler.ts` hinzu.

6. **UI anpassen**

Erweitere das Dashboard in `app/page.tsx`.

## ğŸ“Š Performance

- **Asynchrones Scraping:** Nicht-blockierende AusfÃ¼hrung
- **Indexierte Datenbank:** Schnelle Queries durch Indizes
- **WAL-Modus:** Write-Ahead Logging fÃ¼r bessere Concurrency
- **Pagination:** Effiziente Daten-Verarbeitung groÃŸer Mengen
- **Caching:** Browser-Caching fÃ¼r statische Assets

## ğŸ”’ Sicherheit

- Keine Authentifizierung in dieser Version (read-only Dashboard)
- SQL Injection-Schutz durch Prepared Statements
- XSS-Schutz durch React's automatisches Escaping
- Rate-Limiting fÃ¼r Scraper (1 Sekunde Pause zwischen Seiten)

## ğŸ› Troubleshooting

### Playwright-Fehler

```bash
npx playwright install
```

### Datenbank-Fehler

LÃ¶sche die Datenbank und starte neu:

```bash
rm -rf data/
npm run dev
```

### Port bereits in Verwendung

Ã„ndere den Port in `package.json`:

```json
"dev": "next dev -p 3001"
```

## ğŸ“œ Lizenz

ISC

## ğŸ‘¥ Contributing

Contributions sind willkommen! Bitte erstelle einen Pull Request.

## ğŸ“ Kontakt

Bei Fragen oder Problemen erstelle bitte ein Issue im Repository.

---

**Made with â¤ï¸ for Braunschweig Journalists**
